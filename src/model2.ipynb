{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soil Type Classification using Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_directory = 'new_image_dataset/train'\n",
    "test_data_directory = 'new_image_dataset/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # open cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "load_model = tf.keras.models.load_model\n",
    "image = tf.keras.preprocessing.image\n",
    "ImageDataGenerator = tf.keras.preprocessing.image.ImageDataGenerator\n",
    "Sequential = tf.keras.models.Sequential\n",
    "Dense = tf.keras.layers.Dense\n",
    "Activation = tf.keras.layers.Activation\n",
    "Flatten = tf.keras.layers.Flatten\n",
    "Conv2D = tf.keras.layers.Conv2D\n",
    "MaxPooling2D = tf.keras.layers.MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 565 images belonging to 8 classes.\n",
      "Found 573 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# initiate data preprocessing tools\n",
    "\n",
    "# This step processes the images into a format that\n",
    "# 1. makes the data readable to the model\n",
    "# 2. provides more training material for the model to train from\n",
    "# the `training_data_processor` below scales the data so that it can be\n",
    "# a model input, but also takes each image and augments it so that\n",
    "# the model can learn from multiple variations of the same image.\n",
    "# it flips it horizontally, rotates it, shifts it, and more so that \n",
    "# the model learns from the soil photo rather than the orientation size\n",
    "training_data_processor  = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    horizontal_flip = True,\n",
    "    zoom_range = 0.2,\n",
    "    rotation_range = 10,\n",
    "    shear_range = 0.2,\n",
    "    height_shift_range = 0.1,\n",
    "    width_shift_range = 0.1,\n",
    ")\n",
    "# for the testing images, we don't need to create multiple variatinos\n",
    "test_data_processor = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "# load data into python\n",
    "\n",
    "training_data = training_data_processor.flow_from_directory(\n",
    "    train_data_directory,\n",
    "    target_size = (256, 256), # pixels\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical',\n",
    ")\n",
    "\n",
    "testing_data = test_data_processor.flow_from_directory(\n",
    "    test_data_directory,\n",
    "    target_size = (256, 256),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose model parameters\n",
    "num_conv_layers = 4\n",
    "num_dense_layers = 3\n",
    "layer_size = 29 # limit the layer size as we dont want to over fit the model\n",
    "num_training_epochs = 50\n",
    "MODEL_NAME = 'final_model'\n",
    "\n",
    "CLASSES = ['alike','clay', 'gravel', 'humus', 'not', 'sand', 'silt',' yellow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "18/18 [==============================] - 29s 2s/step - loss: 1.8756 - accuracy: 0.2991 - val_loss: 1.7215 - val_accuracy: 0.3368\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 31s 2s/step - loss: 1.5866 - accuracy: 0.4407 - val_loss: 1.3922 - val_accuracy: 0.5131\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 29s 2s/step - loss: 1.3368 - accuracy: 0.5080 - val_loss: 1.1537 - val_accuracy: 0.5480\n",
      "Epoch 4/50\n",
      "11/18 [=================>............] - ETA: 9s - loss: 1.1200 - accuracy: 0.5767 "
     ]
    }
   ],
   "source": [
    "# initiate model variable\n",
    "model = Sequential()\n",
    "\n",
    "# begin adding properties to model variable\n",
    "# e.g. add a convulutional layer\n",
    "model.add(Conv2D(layer_size, (3,3), input_shape=(256, 256, 3)))\n",
    "model.add(Activation('relu')) # rectified linear unit\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# add additional convolutional layers based on num_conv_layers\n",
    "for _ in range(num_conv_layers-1):\n",
    "    model.add(Conv2D(layer_size, (3,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# reduce dimensionality\n",
    "model.add(Flatten())\n",
    "\n",
    "# add fully connected \"dense\" layers if specified\n",
    "for _ in range(num_dense_layers):\n",
    "    model.add(Dense(layer_size))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(len(CLASSES)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# compile the sequential model with all added properties\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# use the data already loaded to train/tune the model\n",
    "model_results = model.fit(\n",
    "    training_data,\n",
    "    epochs = num_training_epochs, \n",
    "    validation_data = testing_data)\n",
    "\n",
    "# save the trained model\n",
    "model.save(f'{MODEL_NAME}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = model.evaluate(testing_data)\n",
    "\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "training_dataframe = pd.DataFrame(model_results.history)\n",
    "plt.plot(training_dataframe['accuracy'], label='Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(testing_data)\n",
    "y_predicted = [x.argmax() for x in y_predicted]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matrix = confusion_matrix(testing_data.classes, y_predicted)\n",
    "\n",
    "import seaborn as sb\n",
    "\n",
    "sb.heatmap(matrix, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(image_fp):\n",
    "    im = cv2.imread(image_fp) # load the image from the given file path (image_fp)\n",
    "    plt.imshow(im[:,:,[2,1,0]]) # swap the colors because open-cv swaps the rgb colors\n",
    "    img = image.load_img(image_fp, target_size = (256, 256))\n",
    "    img = image.img_to_array(img)\n",
    "\n",
    "    image_array = img / 255. # scale the image\n",
    "    img_batch = np.expand_dims(image_array, axis = 0)\n",
    "\n",
    "    class_ = CLASSES # possible output values\n",
    "    from tensorflow import keras\n",
    "    model = keras.models.load_model('final_model.h5')\n",
    "    predicted_value = model.predict(img_batch)\n",
    "    \n",
    "    out  = f\"\"\"\n",
    "     alike: {predicted_value[0][0]:.5f}\n",
    "      clay: {predicted_value[0][1]:.5f}\n",
    "    gravel: {predicted_value[0][2]:.5f}\n",
    "     humus: {predicted_value[0][3]:.5f}\n",
    "       not: {predicted_value[0][4]:.5f}\n",
    "      peat: {predicted_value[0][5]:.5f}\n",
    "      peat: {predicted_value[0][6]:.5f}\n",
    "    yellow: {predicted_value[0][7]:.5f}\n",
    "\n",
    "    Result: {(predicted_value[0][predicted_value.argmax()] * 100):.2f}% {class_[predicted_value.argmax()]}\n",
    "\n",
    "    \"\"\"\n",
    "  # accuracy: {(accuracy[1]*100):.5f}\n",
    "  #     loss: {(accuracy[0]*100):.5f}\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_file_path = test_data_directory + '/alike/IMG_20221001_105510.jpg'\n",
    "test_prediction = classify(test_image_file_path)\n",
    "\n",
    "print(test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert final_model.h5 to TFLITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model('final_model.h5')\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open(\"final_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system(\"\"\"\n",
    "tensorflowjs_converter --input_format keras \\\n",
    "\tfinal_model.h5 \\\n",
    "\ttfjs\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "39e76dcb4e289f897dc5deee5e893203b7ca595ba0cf32b72c44b371ee523a19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
